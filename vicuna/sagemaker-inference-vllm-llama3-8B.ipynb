{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a329f0",
   "metadata": {},
   "source": [
    "# vLLM chatglm3 rollingbatch deployment guide\n",
    "In this tutorial, you will use LMI container from DLC to SageMaker and run inference with it.\n",
    "\n",
    "Please make sure the following permission granted before running the notebook:\n",
    "\n",
    "- S3 bucket push access\n",
    "- SageMaker access\n",
    "\n",
    "## Step 1: Let's bump up SageMaker and import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec9ac353",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment\n",
    "bucket = sess.default_bucket()\n",
    "s3_client = boto3.client(\"s3\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a15edb2c-a2db-42cb-9993-e1595210c1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04acc720e96d4d7cbb67e6ef07ce729b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb6ec68aefa74eae81de3d24f441cc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c62ede5b554a9ca41473db5d9484b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54d4cb40fcd48c6951fe5b6a6f6ef9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/7.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4cc6f374b34d8c9017849a559bdd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d281a692160b49a68e299dda772d6361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/43.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f7fcbe0a1a46188b2375123bd7fe00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b9d6b5b8074acd897001afc2523437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f722573dd4af495d94d8e5e5edc9019c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc91dc418524f42a8395e527b63eba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58044702edce41d1bb4cfe4422721b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/97.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0044e37a02584ac593c317171488ce65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89df23d5f0a546838161e8d17ca8ffaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d728411501ea4210bd94998d06aaaee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "local_cache_path = Path(\"./model\")\n",
    "local_cache_path.mkdir(exist_ok=True)\n",
    "\n",
    "#model_name = \"THUDM/chatglm3-6b\"\n",
    "model_name = \"shenzhi-wang/Llama3-8B-Chinese-Chat\"\n",
    "\n",
    "# Only download pytorch checkpoint files\n",
    "allow_patterns = [\"*.json\", \"*.pt\", \"*.bin\", \"*.model\", \"*.py\", \"*.txt\"]\n",
    "\n",
    "model_download_path = snapshot_download(\n",
    "    repo_id=model_name,\n",
    "    cache_dir=local_cache_path,\n",
    "    #allow_patterns=allow_patterns,\n",
    "    #revision='f2cc3a689c5eba7dc7fd3757d0175d312d167604'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec5d059-28ed-4ace-a764-70e91cc23ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/models--shenzhi-wang--Llama3-8B-Chinese-Chat/snapshots/4754413429ccde4f441fe30e44ee62fd1c93b8be/config.json\n",
      "./model/models--shenzhi-wang--Llama3-8B-Chinese-Chat/snapshots/4754413429ccde4f441fe30e44ee62fd1c93b8be/\n"
     ]
    }
   ],
   "source": [
    "# Get the model files path\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "local_model_path = None\n",
    "\n",
    "paths = os.walk(r'./model')\n",
    "\n",
    "for root, dirs, files in paths:\n",
    "    for file in files:\n",
    "        if file == 'config.json':\n",
    "            print(os.path.join(root,file))\n",
    "            local_model_path = str(os.path.join(root,file))[0:-11]\n",
    "            print(local_model_path)\n",
    "if local_model_path == None:\n",
    "    print(\"Model download may failed, please check prior step!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430666b8-c437-4537-901f-74914beb4413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-03 06:24:21--  https://github.com/peak/s5cmd/releases/download/v2.1.0/s5cmd_2.1.0_Linux-64bit.tar.gz\n",
      "Resolving github.com (github.com)... 140.82.116.3\n",
      "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/73909333/3a3f9cd5-4172-4aac-b3b4-770410201538?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240703%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240703T062421Z&X-Amz-Expires=300&X-Amz-Signature=6878b1ea021c439433c4364c2687b71a23fc02bf3f2b127b152ad427f1ebdc0d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=73909333&response-content-disposition=attachment%3B%20filename%3Ds5cmd_2.1.0_Linux-64bit.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-07-03 06:24:21--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/73909333/3a3f9cd5-4172-4aac-b3b4-770410201538?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240703%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240703T062421Z&X-Amz-Expires=300&X-Amz-Signature=6878b1ea021c439433c4364c2687b71a23fc02bf3f2b127b152ad427f1ebdc0d&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=73909333&response-content-disposition=attachment%3B%20filename%3Ds5cmd_2.1.0_Linux-64bit.tar.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4531624 (4.3M) [application/octet-stream]\n",
      "Saving to: ‘s5cmd_2.1.0_Linux-64bit.tar.gz’\n",
      "\n",
      "100%[======================================>] 4,531,624   --.-K/s   in 0.1s    \n",
      "\n",
      "2024-07-03 06:24:21 (34.8 MB/s) - ‘s5cmd_2.1.0_Linux-64bit.tar.gz’ saved [4531624/4531624]\n",
      "\n",
      "CHANGELOG.md\n",
      "LICENSE\n",
      "README.md\n",
      "s5cmd\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/peak/s5cmd/releases/download/v2.1.0/s5cmd_2.1.0_Linux-64bit.tar.gz\n",
    "!tar xvzf s5cmd_2.1.0_Linux-64bit.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80500f65-3a27-4c80-a221-c2ec8e3d3be2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR \"sync /home/ec2-user/SageMaker/lmi/model/models--shenzhi-wang--Llama3-8B-Chinese-Chat/snapshots/4754413429ccde4f441fe30e44ee62fd1c93b8be/ s3://sagemaker-us-west-2-687912291502/models/llama3_model/\": given object /home/ec2-user/SageMaker/lmi/model/models--shenzhi-wang--Llama3-8B-Chinese-Chat/snapshots/4754413429ccde4f441fe30e44ee62fd1c93b8be/ not found\n"
     ]
    }
   ],
   "source": [
    "!chmod +x ./s5cmd\n",
    "!./s5cmd sync /home/ec2-user/SageMaker/vllm/model/models--shenzhi-wang--Llama3-8B-Chinese-Chat/snapshots/4754413429ccde4f441fe30e44ee62fd1c93b8be/ s3://sagemaker-us-west-2-687912291502/models/llama3_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81deac79",
   "metadata": {},
   "source": [
    "## Step 2: Start preparing model artifacts\n",
    "In LMI contianer, we expect some artifacts to help setting up the model\n",
    "- serving.properties (required): Defines the model server settings\n",
    "- model.py (optional): A python file to define the core inference logic\n",
    "- requirements.txt (optional): Any additional pip wheel need to install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dc17743-c9f9-4699-b110-89b54da9ed45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login-password --region us-west-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-west-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4883492a-7bcf-4d6c-aad0-33303312fcfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## define repo name, should contain *sagemaker* in the name\n",
    "repo_name = \"sagemaker-vllm-llama3-inference-demo\"\n",
    "endpoint_name=\"vllm-llama3-2024-07-04-12-23-03-924\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a0531bc-2d2f-49c9-9ac0-63406e121748",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image going to be used is ---- > 763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.27.0-deepspeed0.12.6-cu121\n"
     ]
    }
   ],
   "source": [
    "inference_image_uri = image_uris.retrieve(\n",
    "    framework=\"djl-deepspeed\",\n",
    "    region=sess.boto_session.region_name,\n",
    "    version=\"0.27.0\"\n",
    ")\n",
    "print(f\"Image going to be used is ---- > {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede9f3c7-2d46-4f67-80f7-11c24fe64386",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 暂时不需要重新打包镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6f5c79-49cb-42d8-ac75-be57037b79a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile.inference\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile.inference\n",
    "## You should change below region code to the region you used, here sample is use us-west-2\n",
    "From 763104351884.dkr.ecr.us-west-2.amazonaws.com/djl-inference:0.26.0-deepspeed0.12.6-cu121 \n",
    "\n",
    "ENV LANG=C.UTF-8\n",
    "ENV PYTHONUNBUFFERED=TRUE\n",
    "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
    "\n",
    "###升级cuda driver到cu121\n",
    "#RUN apt remove --autoremove nvidia-cuda-toolkit\n",
    "#RUN apt remove --autoremove nvidia-*\n",
    "#RUN apt update\n",
    "#RUN wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda_12.1.1_530.30.02_linux.run\n",
    "#RUN sh cuda_12.1.1_530.30.02_linux.run\n",
    "\n",
    "## Make all local GPUs visible\n",
    "ENV NVIDIA_VISIBLE_DEVICES=\"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86cec47e-7b01-4c03-9f03-791fccf84686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%script env repo_name=$repo_name bash\n",
    "\n",
    "#!/usr/bin/env bash\n",
    "\n",
    "# This script shows how to build the Docker image and push it to ECR to be ready for use\n",
    "# by SageMaker.\n",
    "\n",
    "# The argument to this script is the image name. This will be used as the image on the local\n",
    "# machine and combined with the account and region to form the repository name for ECR.\n",
    "# The name of our algorithm\n",
    "algorithm_name=${repo_name}\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region}|docker login --username AWS --password-stdin ${fullname}\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build -t ${algorithm_name} -f Dockerfile.inference .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f765c16-90f6-4c10-b714-710bdcfbda57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'687912291502.dkr.ecr.us-west-2.amazonaws.com/sagemaker-vllm-llama3-inference-demo:latest'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The image uri which is build and pushed above\n",
    "inference_image_uri = \"{}.dkr.ecr.{}.amazonaws.com/{}:latest\".format(account_id, region, repo_name)\n",
    "inference_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58cf33",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Start building SageMaker endpoint\n",
    "In this step, we will build SageMaker endpoint from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3776e0d3-1f30-4515-9210-d40f7730d35d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (AccessDenied) when calling the ListObjectsV2 operation: Access Denied\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://jackie-test/checkpoint-2118/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b011bf5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "#option.model_id=s3://sagemaker-us-west-2-687912291502/models/llama3_model/\n",
    "#option.model_id=s3://sagemaker-us-west-2-355817945413/llama3/\n",
    "option.model_id=s3://jackie-test/checkpoint-2118/\n",
    "option.task=text-generation\n",
    "option.trust_remote_code=true\n",
    "option.tensor_parallel_degree=1\n",
    "option.rolling_batch=vllm\n",
    "option.dtype=fp16\n",
    "#option.enable_streaming=true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d955679",
   "metadata": {},
   "source": [
    "### Getting the container image URI\n",
    "\n",
    "[Large Model Inference available DLC](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#large-model-inference-containers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11601839",
   "metadata": {},
   "source": [
    "### Upload artifact on S3 and create SageMaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "444e0469-885e-4366-b599-c478c9fd19b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mymodel/\n",
      "mymodel/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir mymodel\n",
    "mv serving.properties mymodel/\n",
    "tar czvf mymodel.tar.gz mymodel/\n",
    "rm -rf mymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b1e5ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- > s3://sagemaker-us-west-2-687912291502/yafei/llama3/mymodel.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_prefix = \"yafei/llama3\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "code_artifact = sess.upload_data(\"mymodel.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- > {code_artifact}\")\n",
    "\n",
    "model = Model(image_uri=inference_image_uri, model_data=code_artifact, role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f39f6",
   "metadata": {},
   "source": [
    "### 4.2 Create SageMaker endpoint\n",
    "\n",
    "You need to specify the instance to use and endpoint names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e0e61cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------!"
     ]
    }
   ],
   "source": [
    "instance_type = \"ml.g5.4xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"vllm-llama3\")\n",
    "\n",
    "model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             endpoint_name=endpoint_name,\n",
    "             # container_startup_health_check_timeout=3600\n",
    "            )\n",
    "\n",
    "# our requests and responses will be in json format so we specify the serializer and the deserializer\n",
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63ee65",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 5: Test and benchmark the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "236e77f0-b1f2-471f-a564-bae548fd4ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def extract_unicode_chars(text):\n",
    "    pattern = r'\\\\u([\\dA-Fa-f]{4})'\n",
    "    result = re.sub(pattern, lambda m: chr(int(m.group(1), 16)), text)\n",
    "    return result\n",
    "\n",
    "\n",
    "class StreamScanner:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.buff = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "        \n",
    "    def write(self, content):\n",
    "        self.buff.seek(0, io.SEEK_END)\n",
    "        self.buff.write(content)\n",
    "        \n",
    "    def readlines(self):\n",
    "        self.buff.seek(self.read_pos)\n",
    "        for line in self.buff.readlines():\n",
    "            if line[-1] != b'\\n':\n",
    "                self.read_pos += len(line)\n",
    "                yield line[:-1]\n",
    "                \n",
    "    def reset(self):\n",
    "        self.read_pos = 0\n",
    "        \n",
    "        \n",
    "class LineIterator:\n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "            print(line)\n",
    "            if line and line[-1] == ord('\\n'):\n",
    "                self.read_pos += len(line)\n",
    "                return line[:-1]\n",
    "            try:\n",
    "                chunk = next(self.byte_iterator)\n",
    "            except StopIteration:\n",
    "                if self.read_pos < self.buffer.getbuffer().nbytes:\n",
    "                    continue\n",
    "                raise\n",
    "            if 'PayloadPart' not in chunk:\n",
    "                print('Unknown event type:' + chunk)\n",
    "                continue\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk['PayloadPart']['Bytes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a745fa-321f-49c2-94f8-5581003b3301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name=\"vllm-llama3-2024-07-22-06-16-42-251\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bcef095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "                \"max_tokens\": 4096,\n",
    "                #\"do_sample\": True,\n",
    "                \"temperature\": 0.5,\n",
    "                #\"stop_sequences\": \"<|eot_id|>\"\n",
    "            }\n",
    "\n",
    "prompt_live=\"\"\"Create a captivating product promotion script for an e-commerce live broadcast host based on the following product detailed description.\n",
    "[The iPhone 14 is the latest phone officially released by Apple on September 8, 2022. It is equipped with a 6.1-inch OLED screen and offers six unique color choices: blue, purple, midnight, starlight, red, and yellow. The phone has an elegant size design, with a length of 146.7mm, a width of 71.5mm, a thickness of 7.8mm, and weighs about 172 grams. In terms of performance, the iPhone 14 is equipped with a powerful Apple A15 bionic chip, which contains a 6-core central processor, including 2 performance cores and 4 efficiency cores, and a 5-core GPU graphics processor. It not only supports practical features such as accident detection and satellite communication but also performs excellently in photography. The rear camera includes a 12-megapixel main lens and a 12-megapixel ultra-wide-angle lens, and the front camera is also 12 megapixels. In addition, the phone also supports photographic technologies such as optical engine, deep fusion technology, smart HDR 4, and portrait mode, ensuring that users can easily capture every beautiful moment.]\n",
    "The script should include the main features and advantages of the product as well as interactive segments, be written in Chinese, and be concise, interesting, and attractive, ensuring to contain all the elements mentioned above.\n",
    "\"\"\"\n",
    "prompt1 = \"\"\"根据以下反引号内的商品详细描述，为电商直播主持人创作一段引人注目的商品推介话术\n",
    "‘’‘\n",
    "iPhone 14是苹果公司在2022年9月8日正式发布的最新手机。它配备了一块6.1英寸的OLED屏幕，并提供了六种独特的颜色选择：蓝色、紫色、午夜色、星光色、红色和黄色。手机的尺寸设计优雅，长度为146.7毫米，宽度为71.5毫米，厚度为7.8毫米，重量约为172克。\n",
    "在性能上，iPhone 14搭载了强大的苹果A15仿生芯片，内部含有6 核中央处理器，有 2 个性能核心和 4 个能效核心，还有5 核GPU图形处理器。。它不仅支持车祸检测和卫星通信等实用功能，而且在拍照方面也表现出色。\n",
    "后置摄像头包括一个1200万像素的主镜头和一个1200万像素的超广角镜头，前置摄像头也是1200万像素\n",
    "此外，该手机还支持光像引擎、深度融合技术、智能HDR4和人像模式等摄影技术，确保用户可以轻松捕捉每一个美好瞬间\n",
    "’‘’\n",
    "话术中应包括商品的主要特点、优势及互动环节,使用中文撰写，并保持话术简洁、有趣且具吸引力,并确保包含上述要求的所有元素\"\"\"\n",
    "\n",
    "prompt2=\"\"\"根据以下反引号内的关键词，为电商直播主持人创作一段通用的开场、互动或欢迎话术。请确保话术融入这些关键词，使用中文撰写，内容要简洁、有趣且具吸引力，同时适应广泛的商品和场景。\n",
    "‘’‘\n",
    "精选\n",
    "性价比\n",
    "品质\n",
    "日常家居\n",
    "穿搭\n",
    "限时折扣\n",
    "免费赠品\n",
    "抽奖活动\n",
    "大品牌合作\n",
    "独家优惠\n",
    "’‘’\n",
    "请使用上述关键词，编写一段具有普遍适用性，适于电商直播开头或互动环节的话术\"\"\"\n",
    "\n",
    "\n",
    "prompt3=\"\"\"\n",
    "请根据以下反引号内的商品描述、意图、问题模板和回答模板，为电商直播商品生成一个问答库。要求生成的回答应当有至少一组，最多五组。请确保答案基于商品描述和回答模板生成。如果无法生成回答，表示为“根据已知信息无法生成回答”。格式应如下：{{\"Q\":\"问题\",\"A\":['答案1-1','答案1-2'...]}}\n",
    "‘’‘\n",
    "商品描述：iPhone 14是苹果公司在2022年9月8日正式发布的最新手机。它配备了一块6.1英寸的OLED屏幕，并提供了六种独特的颜色选择：蓝色、紫色、午夜色、星光色、红色和黄色。手机的尺寸设计优雅，长度为146.7毫米，宽度为71.5毫米，厚度为7.8毫米，重量约为172克。\n",
    "在性能上，iPhone 14搭载了强大的苹果A15仿生芯片，内部含有6 核中央处理器，有 2 个性能核心和 4 个能效核心，还有5 核GPU图形处理器。。它不仅支持车祸检测和卫星通信等实用功能，而且在拍照方面也表现出色。后置摄像头包括一个1200万像素的主镜头和一个1200万像素的超广角镜头，前置摄像头也是1200万像素。此外，该手机还支持光像引擎、深度融合技术、智能HDR4和人像模式等摄影技术，确保用户可以轻松捕捉每一个美好瞬间。}\n",
    "意图：性能\n",
    "问题模板：手机的性能如何？\n",
    "回答模板：[商品名称]采用了最新的[芯片名称]，搭载了[核心数量]核CPU和[GPU核心数量]核GPU，为用户提供强大的性能。\n",
    "谈到[商品名称]的性能，不得不提及它的[芯片名称]，配备[核心数量]核CPU和[GPU核心数量]核GPU，应对各种任务都游刃有余。\n",
    "[商品名称]在性能上表现卓越，得益于其[芯片名称]和[核心数量]核处理器，加上[GPU核心数量]核GPU，让每次使用都顺畅无比。}\n",
    "’‘’\n",
    "问答生成：请基于上述商品描述、意图、问题模板和回答模板，为电商直播商品提供符合上述格式的问答库。\n",
    "\"\"\"\n",
    "\n",
    "prompt4=\"\"\"\n",
    "请以电商直播主持人的第一人称角度回答观众的商品相关问题。确保只回答与商品相关的问题，并只使用以下反引号内知识库的信息来回答。回答中请勿随意编造内容。格式应如下:[{{\"intention\": \"意图1\", \"answer\": \"回答1\"}},{{\"intention\": \"意图2\", \"answer\": \"回答2\"}}]\n",
    "‘’‘\n",
    "[问题：iPhone 14有哪些可选的颜色？][回答：iPhone 14提供了六种时尚的颜色选择，包括蓝色、紫色、午夜色、星光色、红色和黄色。][意图：颜色]\n",
    "[问题：关于摄像头，iPhone 14的前置和后置摄像头分辨率是多少？][回答：iPhone 14的前置和后置摄像头分辨率都是1200万像素。][意图：分辨率]\n",
    "[问题：我经常用手机办公和玩游戏，iPhone 14的性能如何？][回答：iPhone 14搭载了强大的苹果A15六核中央处理器，无论是玩游戏、看视频，还是办公，它都可以轻松应对。][意图：性能]}\n",
    "’‘’\n",
    "观众问题：主播小姐姐好漂亮\n",
    "使用第一人称直接回答观众关于商品的提问。检查知识库中是否有与观众提问相匹配的回答。对于在知识库中找到的每个匹配意图，请依次提供对应的回答，并确保从知识库中的意图中提取相应的意图标签。如果所有的意图都在知识库中找不到答案，回答“根据已知信息无法回答问题”。确保不使用emoji。\n",
    "\"\"\"\n",
    "\n",
    "other=\"\"\"我很在意手机的颜色和摄像头功能，能给我介绍一下iPhone 14在这两方面的特点吗？\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a459e3e-376b-4168-bdd3-9aa91a77f2c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_new = \"\"\"\n",
    "You are a senior cross-border e-commerce product consultant, \n",
    "your task is write keyword for platform ebay based on the title, \n",
    "description provided by the user, \n",
    "answer in format a dictionary of[keyword_type: keyword]. \n",
    "the input title is \n",
    "```36MM Quartz Clock Inserts Movement Replacement DIY Gold Arabic Numbers```, \n",
    "input product description is \n",
    "```Features:\\n\\n\n",
    "*36MM Quartz Clock Inserts Movement Replacement:This clock insert has a diameter of 36mm and comes with a rubber ring to securely fix it onto a clock base.\\n\\n\n",
    "*Gold Silvery Arabic Numbers on White Dial: The white dial features Arabic numbers, transparent lens, and a gold border.\\n\\n\n",
    "*Precise and High-Quality Clock Movement: The clock movement ensures accurate timekeeping and is of superior quality.\\n\\n\n",
    "*Versatile Usage: It can be used for DIY clock projects or for repairing or replacing damaged clocks.\\n\\n\n",
    "*Suitable for Quartz Clocks: This clock insert is compatible with quartz clocks and serves as a perfect replacement part.\\n\\n\\n\\n\n",
    "\n",
    "Specifications:\n",
    "*Part Name:Quartz Clock Inserts\n",
    "*Material:Plastic+metal\n",
    "*Size:as shown\n",
    "*Color:Gold，silver\n",
    "*Battery: 1*AAA battery not included\n",
    "Package Content:\n",
    "1 * Quartz Clock Inserts```\n",
    "\n",
    "what's the keywords? \n",
    "Present the answer in a dictionary format,where the keys are the names inside  [\\\"Primary Keywords\\\",\\\"Attribute Keywords\\\"] ,and the values are lists containing the keywords.\n",
    "Output directly in json format without any prefix.\n",
    "Only output the text that completes the task, without outputting any other redundant information\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a32abdb-0e43-46af-9d0d-5687d8180a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start invoke timestamp: 2024-07-22 13:50:51\n",
      "{\"generated_text\": \"Phone\n",
      "{\"generated_text\": \"Phone \n",
      "{\"generated_text\": \"Phone 14\n",
      "{\"generated_text\": \"Phone 14output\n",
      "{\"generated_text\": \"Phone 14output result\n",
      "{\"generated_text\": \"Phone 14output result is\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Un\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbr\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*F\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*Fitting\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*Fitting \\\"\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*Fitting \\\"],\\\"\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*Fitting \\\"],\\\"MP\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*Fitting \\\"],\\\"MPN\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*Fitting \\\"],\\\"MPN\\\":[\\\"\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*Fitting \\\"],\\\"MPN\\\":[\\\"Does\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*Fitting \\\"],\\\"MPN\\\":[\\\"Does Not\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*Fitting \\\"],\\\"MPN\\\":[\\\"Does Not Apply\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*Fitting \\\"],\\\"MPN\\\":[\\\"Does Not Apply\\\"],\\\"\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*Fitting \\\"],\\\"MPN\\\":[\\\"Does Not Apply\\\"],\\\"Package\n",
      "{\"generated_text\": \"Phone 14output result is {\\\"Brand\\\":[\\\"Unbranded\\\"],\\\"Type\\\":[\\\"1*Fitting \\\"],\\\"MPN\\\":[\\\"Does Not Apply\\\"],\\\"Package Contents\"}\n",
      "CPU times: user 30.4 ms, sys: 2.1 ms, total: 32.5 ms\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from joblib import Parallel, delayed\n",
    "import json\n",
    "import codecs\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "prompts = [prompt1,prompt2,prompt3,prompt4,prompt_live,prompt2,prompt4,prompt1]\n",
    "#for i in range(8):\n",
    "#    prompts.append(prompt4)\n",
    "#prompts = [prompt_new,prompt_new,prompt_new,prompt_new,prompt_new,prompt_new,prompt_new,prompt_new]\n",
    "def call_endpoint(prompt):\n",
    "    current_time = datetime.datetime.now()\n",
    "    formatted_time = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(\"start invoke timestamp:\", formatted_time)\n",
    "    response_model = smr_client.invoke_endpoint_with_response_stream(\n",
    "            EndpointName=endpoint_name,\n",
    "            Body=json.dumps(\n",
    "            {\n",
    "                \"inputs\": prompt,\n",
    "                \"parameters\": parameters\n",
    "            }\n",
    "            ),\n",
    "            ContentType=\"application/json\",\n",
    "        )\n",
    "\n",
    "    event_stream = response_model['Body']\n",
    "    result_all = \"\"\n",
    "    for event in event_stream:\n",
    "        eventJson=event['PayloadPart']['Bytes'].decode('utf-8')\n",
    "        result_all=result_all+eventJson\n",
    "        print(result_all)\n",
    "        #output=extract_unicode_chars(eventJson)\n",
    "        #print(eventJson)\n",
    "        \n",
    "\n",
    "call_endpoint(other)\n",
    "\n",
    "#results = Parallel(n_jobs=8, prefer='threads', verbose=1, )(\n",
    "#    delayed(call_endpoint)(prompt1)\n",
    "#    for i in range(8)\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbd0ec1-dba7-47d7-9268-a23e2c3609fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time:1\n",
      "{'generated_text': 'output result is {\"Primary Keywords\": [\"Quartz Clock Inserts\", \"Quarzuhreins\\\\u00e4tze\"], \"Attribute Keywords'}\n",
      "CPU times: user 3.87 ms, sys: 0 ns, total: 3.87 ms\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "prompts = [prompt_live,prompt_live,prompt_live]\n",
    "prompt = \"\"\"\n",
    "You are a senior cross-border e-commerce product consultant, \n",
    "your task is write keyword for platform ebay based on the title, \n",
    "description provided by the user, \n",
    "answer in format a dictionary of[keyword_type: keyword]. \n",
    "the input title is \n",
    "```36MM Quartz Clock Inserts Movement Replacement DIY Gold Arabic Numbers```, \n",
    "input product description is \n",
    "```Features:\\n\\n\n",
    "*36MM Quartz Clock Inserts Movement Replacement:This clock insert has a diameter of 36mm and comes with a rubber ring to securely fix it onto a clock base.\\n\\n\n",
    "*Gold Silvery Arabic Numbers on White Dial: The white dial features Arabic numbers, transparent lens, and a gold border.\\n\\n\n",
    "*Precise and High-Quality Clock Movement: The clock movement ensures accurate timekeeping and is of superior quality.\\n\\n\n",
    "*Versatile Usage: It can be used for DIY clock projects or for repairing or replacing damaged clocks.\\n\\n\n",
    "*Suitable for Quartz Clocks: This clock insert is compatible with quartz clocks and serves as a perfect replacement part.\\n\\n\\n\\n\n",
    "\n",
    "Specifications:\n",
    "*Part Name:Quartz Clock Inserts\n",
    "*Material:Plastic+metal\n",
    "*Size:as shown\n",
    "*Color:Gold，silver\n",
    "*Battery: 1*AAA battery not included\n",
    "Package Content:\n",
    "1 * Quartz Clock Inserts```\n",
    "\n",
    "what's the keywords? \n",
    "Present the answer in a dictionary format,where the keys are the names inside  [\\\"Primary Keywords\\\",\\\"Attribute Keywords\\\"] ,and the values are lists containing the keywords.\n",
    "Output directly in json format without any prefix.\n",
    "Only output the text that completes the task, without outputting any other redundant information\n",
    "\"\"\"\n",
    "\n",
    "def call_endpoint(prompt):\n",
    "    input = {\"inputs\": prompt, \"parameters\": parameters}\n",
    "    input = json.dumps(input)\n",
    "    start = time.time()\n",
    "\n",
    "    response = smr_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                       ContentType='application/json',\n",
    "                                       Accept='application/json',\n",
    "                                       Body=input)\n",
    "    results = response['Body'].read().decode(\"utf-8\")\n",
    "    end = time.time()\n",
    "    process_time=end-start\n",
    "    print(\"process time:\"+str(int(process_time)))\n",
    "    ouputJson=json.loads(results)\n",
    "    print(ouputJson)\n",
    "\n",
    "call_endpoint(prompt)\n",
    "    \n",
    "#results = Parallel(n_jobs=3, prefer='threads', verbose=1)(\n",
    "#    delayed(call_endpoint)(prompt)\n",
    "#    for prompt in prompts\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cd9042",
   "metadata": {},
   "source": [
    "## Clean up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d674b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
